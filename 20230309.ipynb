{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Sequential API (순서대로 하는거에 좋다)\n",
    "model = keras.Sequential(name = 'Sequential')\n",
    "model.add(keras.layers.Input(shape = (32, )))\n",
    "model.add(keras.layers.Dense(units = 32, activation = 'relu', name = 'hidden1'))\n",
    "# model.add(keras.layers.Dense(units = 32, input_shape = (32, ), activation = 'relu', name = 'hidden1'))\n",
    "model.add(keras.layers.Dense(16, activation = 'relu', name = 'hidden2'))\n",
    "model.add(keras.layers.Dense(1, activation = 'sigmoid', name = 'output'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Function_API\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 32)]              0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Functional API (모델의 자유도 면에서 더 좋다)\n",
    "inputs = keras.layers.Input(shape = (32, ), name = 'Input')\n",
    "hidden1 = keras.layers.Dense(32, activation = 'relu', name = 'hidden1')(inputs)\n",
    "hidden2 = keras.layers.Dense(16, 'relu', name = 'hidden2')(hidden1)\n",
    "outputs = keras.layers.Dense(1, 'sigmoid', name = 'output')(hidden2)\n",
    "\n",
    "model_functional = keras.Model(inputs, outputs, name = 'Function_API')\n",
    "model_functional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subclassing (함수 콜을 할때 unit을 수정할 수 있음)\n",
    "class mymodel(keras.Model):\n",
    "    def __init__(self, hidden1, hidden2, outputs):\n",
    "        super(mymodel, self).__init__(name = 'subclassing')\n",
    "        self.dense1 = keras.layers.Dense(hidden1, 'relu', name = 'hidden1')\n",
    "        self.dense2 = keras.layers.Dense(hidden2, 'relu', name = 'hidden2')\n",
    "        self.outputs = keras.layers.Dense(outputs, 'sigmoid', name = 'outputs')\n",
    "\n",
    "    def call(self, inptus):\n",
    "        x = self.dense1(inptus)\n",
    "        x = self.dense2(x)\n",
    "        x = self.outputs(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "mymodel_subclass = mymodel(32, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel_subclass.build(input_shape=(1, 32, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"subclassing\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             multiple                  1056      \n",
      "                                                                 \n",
      " hidden2 (Dense)             multiple                  528       \n",
      "                                                                 \n",
      " outputs (Dense)             multiple                  17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel_subclass.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(keras.Model):\n",
    "    def __init__(self, hidden1, hidden2, outputs):\n",
    "        super(mymodel, self).__init__(name = 'subclass')\n",
    "        self.dense1 = keras.layers.Dense(hidden1, 'relu', name = 'hidden1')\n",
    "        self.dense2 = keras.layers.Dense(hidden2, 'relu', name = 'hidden2')\n",
    "        self.outputs = keras.layers.Dense(outputs, 'sigmoid', name = 'outputs')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.outputs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel_subclass = mymodel(32, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"subclass\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             multiple                  1056      \n",
      "                                                                 \n",
      " hidden2 (Dense)             multiple                  528       \n",
      "                                                                 \n",
      " outputs (Dense)             multiple                  17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel_subclass.build(input_shape=(1, 32, ))\n",
    "mymodel_subclass.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 1)             0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 20, 10)            40        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 6, 10)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 60)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                3050      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,600\n",
      "Trainable params: 3,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Funtional API (Conv1D)\n",
    "inputs = keras.layers.Input(shape = (20, 1))\n",
    "dropouts = keras.layers.Dropout(rate = 0.2)(inputs)\n",
    "conv = keras.layers.Conv1D(filters = 10, kernel_size = 3, padding = 'same', activation = 'relu')(dropouts)\n",
    "max_pool = keras.layers.MaxPool1D(3)(conv)\n",
    "flatten = keras.layers.Flatten()(max_pool)\n",
    "hidden = keras.layers.Dense(50, activation='relu')(flatten)\n",
    "outputs = keras.layers.Dense(10, activation = 'softmax')(hidden)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(keras.Model):\n",
    "    def __init__(self, hidden1, hidden2, outputs):\n",
    "        super(mymodel, self).__init__(name = 'subclassing')\n",
    "        self.dense1 = keras.layers.Dense(hidden1, 'relu', name = 'hidden1')\n",
    "        self.dense2 = keras.layers.Dense(hidden2, 'relu', name = 'hidden2')\n",
    "        self.outputs = keras.layers.Dense(outputs, 'sigmoid', name = 'output')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.outputs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"subclassing\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             multiple                  1056      \n",
      "                                                                 \n",
      " hidden2 (Dense)             multiple                  1056      \n",
      "                                                                 \n",
      " output (Dense)              multiple                  330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,442\n",
      "Trainable params: 2,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel_sub = mymodel(32, 32, 10)\n",
    "mymodel_sub.build(input_shape=(1,32, ))\n",
    "mymodel_sub.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피마 인디언으로 예시 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('./pima-indians-diabetes.csv', delimiter=',')\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mymodel(12, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"subclassing\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             multiple                  108       \n",
      "                                                                 \n",
      " hidden2 (Dense)             multiple                  104       \n",
      "                                                                 \n",
      " output (Dense)              multiple                  9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(1, 8, )) # 대상 정보 필요\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='./best_model.hdf5', monitor='val_loss', save_best_only=True)\n",
    "early_stop = keras.callbacks.EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 2s 15ms/step - loss: 14.3631 - acc: 0.3469 - val_loss: 10.7213 - val_acc: 0.3571\n",
      "Epoch 2/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 9.7397 - acc: 0.3800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 14:23:04.026526: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7635 - acc: 0.3648 - val_loss: 4.6397 - val_acc: 0.3896\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.7693 - acc: 0.4707 - val_loss: 1.5627 - val_acc: 0.5455\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5119 - acc: 0.6287 - val_loss: 1.3718 - val_acc: 0.6558\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4047 - acc: 0.6450 - val_loss: 1.0532 - val_acc: 0.5455\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2151 - acc: 0.6156 - val_loss: 1.0403 - val_acc: 0.5455\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.1647 - acc: 0.5847 - val_loss: 0.9871 - val_acc: 0.5519\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1058 - acc: 0.6075 - val_loss: 0.9697 - val_acc: 0.5390\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.0795 - acc: 0.6075 - val_loss: 0.9509 - val_acc: 0.5260\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0553 - acc: 0.6075 - val_loss: 0.9301 - val_acc: 0.5325\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0358 - acc: 0.5993 - val_loss: 0.9089 - val_acc: 0.5325\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0201 - acc: 0.6075 - val_loss: 0.9109 - val_acc: 0.5195\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9990 - acc: 0.5928 - val_loss: 0.8942 - val_acc: 0.5325\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9809 - acc: 0.6010 - val_loss: 0.8791 - val_acc: 0.5260\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9616 - acc: 0.5977 - val_loss: 0.8680 - val_acc: 0.5325\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9480 - acc: 0.6107 - val_loss: 0.8581 - val_acc: 0.5455\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9371 - acc: 0.6059 - val_loss: 0.8591 - val_acc: 0.5195\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9170 - acc: 0.6042 - val_loss: 0.8553 - val_acc: 0.5260\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8998 - acc: 0.6091 - val_loss: 0.8533 - val_acc: 0.5195\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8922 - acc: 0.6124 - val_loss: 0.8335 - val_acc: 0.5325\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8798 - acc: 0.6156 - val_loss: 0.8248 - val_acc: 0.5260\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8607 - acc: 0.6140 - val_loss: 0.8094 - val_acc: 0.5260\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8532 - acc: 0.6221 - val_loss: 0.8034 - val_acc: 0.5584\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8447 - acc: 0.6173 - val_loss: 0.7980 - val_acc: 0.5390\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8241 - acc: 0.6270 - val_loss: 0.7847 - val_acc: 0.5714\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8142 - acc: 0.6450 - val_loss: 0.7801 - val_acc: 0.5455\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8059 - acc: 0.6368 - val_loss: 0.7824 - val_acc: 0.5390\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7919 - acc: 0.6433 - val_loss: 0.7618 - val_acc: 0.5649\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7939 - acc: 0.6254 - val_loss: 0.7519 - val_acc: 0.5714\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7853 - acc: 0.6466 - val_loss: 0.7662 - val_acc: 0.5584\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7676 - acc: 0.6450 - val_loss: 0.7475 - val_acc: 0.6039\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7592 - acc: 0.6482 - val_loss: 0.7433 - val_acc: 0.5909\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7452 - acc: 0.6466 - val_loss: 0.7388 - val_acc: 0.6039\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7547 - acc: 0.6531 - val_loss: 0.7374 - val_acc: 0.5779\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7281 - acc: 0.6482 - val_loss: 0.7334 - val_acc: 0.6234\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7298 - acc: 0.6531 - val_loss: 0.7192 - val_acc: 0.6623\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7238 - acc: 0.6564 - val_loss: 0.7363 - val_acc: 0.5779\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7227 - acc: 0.6515 - val_loss: 0.7167 - val_acc: 0.6299\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7082 - acc: 0.6580 - val_loss: 0.7127 - val_acc: 0.6299\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6976 - acc: 0.6564 - val_loss: 0.7104 - val_acc: 0.6299\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6918 - acc: 0.6498 - val_loss: 0.7076 - val_acc: 0.6169\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6861 - acc: 0.6498 - val_loss: 0.7024 - val_acc: 0.6623\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6820 - acc: 0.6564 - val_loss: 0.7041 - val_acc: 0.6169\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6768 - acc: 0.6661 - val_loss: 0.6943 - val_acc: 0.6494\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6742 - acc: 0.6564 - val_loss: 0.7000 - val_acc: 0.6494\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6677 - acc: 0.6547 - val_loss: 0.6951 - val_acc: 0.6234\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6660 - acc: 0.6531 - val_loss: 0.6968 - val_acc: 0.6299\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6607 - acc: 0.6596 - val_loss: 0.6941 - val_acc: 0.6558\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6615 - acc: 0.6564 - val_loss: 0.6877 - val_acc: 0.6558\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6584 - acc: 0.6694 - val_loss: 0.6841 - val_acc: 0.6234\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6470 - acc: 0.6678 - val_loss: 0.6852 - val_acc: 0.6429\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6461 - acc: 0.6710 - val_loss: 0.6765 - val_acc: 0.6429\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6396 - acc: 0.6775 - val_loss: 0.6764 - val_acc: 0.6299\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6570 - acc: 0.6417 - val_loss: 0.6756 - val_acc: 0.6558\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6714 - acc: 0.6775 - val_loss: 0.6761 - val_acc: 0.6169\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6309 - acc: 0.6661 - val_loss: 0.6653 - val_acc: 0.6364\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6241 - acc: 0.6661 - val_loss: 0.6699 - val_acc: 0.6234\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6250 - acc: 0.6792 - val_loss: 0.6706 - val_acc: 0.6104\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6198 - acc: 0.6645 - val_loss: 0.6582 - val_acc: 0.6364\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6143 - acc: 0.6824 - val_loss: 0.6562 - val_acc: 0.6364\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6139 - acc: 0.6694 - val_loss: 0.6527 - val_acc: 0.6299\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6094 - acc: 0.6759 - val_loss: 0.6442 - val_acc: 0.6299\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6149 - acc: 0.6938 - val_loss: 0.6602 - val_acc: 0.6429\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6139 - acc: 0.6710 - val_loss: 0.6547 - val_acc: 0.6234\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6078 - acc: 0.6775 - val_loss: 0.6616 - val_acc: 0.6429\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6026 - acc: 0.6954 - val_loss: 0.6507 - val_acc: 0.6429\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6006 - acc: 0.6775 - val_loss: 0.6498 - val_acc: 0.6234\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5944 - acc: 0.6808 - val_loss: 0.6413 - val_acc: 0.6299\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6017 - acc: 0.6840 - val_loss: 0.6512 - val_acc: 0.6494\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5978 - acc: 0.7068 - val_loss: 0.6465 - val_acc: 0.6494\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5896 - acc: 0.6906 - val_loss: 0.6490 - val_acc: 0.6234\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5941 - acc: 0.6792 - val_loss: 0.6511 - val_acc: 0.6558\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5920 - acc: 0.7085 - val_loss: 0.6469 - val_acc: 0.6494\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5948 - acc: 0.6743 - val_loss: 0.6407 - val_acc: 0.6234\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5872 - acc: 0.7003 - val_loss: 0.6396 - val_acc: 0.6364\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5781 - acc: 0.7036 - val_loss: 0.6352 - val_acc: 0.6558\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5743 - acc: 0.7068 - val_loss: 0.6357 - val_acc: 0.6429\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5852 - acc: 0.6938 - val_loss: 0.6291 - val_acc: 0.6623\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5713 - acc: 0.7036 - val_loss: 0.6313 - val_acc: 0.6429\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5738 - acc: 0.6906 - val_loss: 0.6350 - val_acc: 0.6558\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5740 - acc: 0.7166 - val_loss: 0.6406 - val_acc: 0.6558\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5775 - acc: 0.7036 - val_loss: 0.6370 - val_acc: 0.6494\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5746 - acc: 0.7199 - val_loss: 0.6305 - val_acc: 0.6494\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5663 - acc: 0.7264 - val_loss: 0.6284 - val_acc: 0.6429\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5661 - acc: 0.7052 - val_loss: 0.6267 - val_acc: 0.6364\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5604 - acc: 0.7052 - val_loss: 0.6253 - val_acc: 0.6688\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5603 - acc: 0.7166 - val_loss: 0.6303 - val_acc: 0.6429\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5625 - acc: 0.7068 - val_loss: 0.6302 - val_acc: 0.6623\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5562 - acc: 0.7020 - val_loss: 0.6293 - val_acc: 0.6364\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5622 - acc: 0.7264 - val_loss: 0.6309 - val_acc: 0.6494\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5598 - acc: 0.7068 - val_loss: 0.6329 - val_acc: 0.6558\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5604 - acc: 0.7003 - val_loss: 0.6295 - val_acc: 0.6558\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5578 - acc: 0.7248 - val_loss: 0.6294 - val_acc: 0.6429\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5602 - acc: 0.7101 - val_loss: 0.6279 - val_acc: 0.6429\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5549 - acc: 0.6971 - val_loss: 0.6229 - val_acc: 0.6558\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5577 - acc: 0.7231 - val_loss: 0.6218 - val_acc: 0.6494\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5516 - acc: 0.7280 - val_loss: 0.6302 - val_acc: 0.6558\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5526 - acc: 0.7117 - val_loss: 0.6148 - val_acc: 0.6429\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5582 - acc: 0.7280 - val_loss: 0.6286 - val_acc: 0.6494\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5703 - acc: 0.7020 - val_loss: 0.6207 - val_acc: 0.6623\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "history = model.fit(X, y, validation_split = 0.2, epochs = 100, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'], 'r', label = 'Validation loss')\n",
    "plt.plot(history.history['loss'], 'b', label = 'Train loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['너 오늘 이뻐 보인다',\n",
    "          '나는 오늘 기분이 더러워',\n",
    "          '끝내주는데, 좋은 일이 있나봐',\n",
    "          '나 좋은 일이 생겼어',\n",
    "          '아 오늘 진짜 짜증나',\n",
    "          '환상적인데, 정말 좋은거 같아']\n",
    "\n",
    "targets = np.array([[1], [0], [1], [1], [0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'오늘': 1, '좋은': 2, '일이': 3, '너': 4, '이뻐': 5, '보인다': 6, '나는': 7, '기분이': 8, '더러워': 9, '끝내주는데': 10, '있나봐': 11, '나': 12, '생겼어': 13, '아': 14, '진짜': 15, '짜증나': 16, '환상적인데': 17, '정말': 18, '좋은거': 19, '같아': 20}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['너 오늘 이뻐 보인다', '나는 오늘 기분이 더러워', '끝내주는데, 좋은 일이 있나봐', '나 좋은 일이 생겼어', '아 오늘 진짜 짜증나', '환상적인데, 정말 좋은거 같아']\n",
      "[[ 4  1  5  6]\n",
      " [ 7  1  8  9]\n",
      " [10  2  3 11]\n",
      " [12  2  3 13]\n",
      " [14  1 15 16]\n",
      " [17 18 19 20]]\n"
     ]
    }
   ],
   "source": [
    "print(samples)\n",
    "print(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "emb_size = 128\n",
    "hidden_dimension = 256\n",
    "output_dimension = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name = 'Sequential_word')\n",
    "model.add(keras.layers.Input(shape=4))\n",
    "model.add(keras.layers.Embedding(vocab_size, emb_size))\n",
    "model.add(keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis = 1)))\n",
    "model.add(keras.layers.Dense(hidden_dimension, 'relu', name = 'hidden1'))\n",
    "model.add(keras.layers.Dense(output_dimension, 'sigmoid', name = 'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_word\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 4, 128)            2688      \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 128)               0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6936 - acc: 0.6667\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6735 - acc: 0.8333\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6575 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6402 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6208 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5964 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5696 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5399 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5019 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4615 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4229 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3776 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3322 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2884 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2464 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2073 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1718 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1397 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1172 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0723 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.9235e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.6762e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.4003e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.1927e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.9362e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.7082e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.4817e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.2770e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.0536e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.8602e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.6605e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.4995e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.3283e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.1467e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.9831e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.8182e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6639e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.5174e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.3741e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.2369e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.1029e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.9771e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.8484e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.7195e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.5975e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f460c2ec190>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequence, targets, epochs=num_epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Functional_API\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " embedding_7 (Embedding)     (None, 4, 128)            2688      \n",
      "                                                                 \n",
      " tf.math.reduce_mean_2 (TFOp  (None, 128)              0         \n",
      " Lambda)                                                         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Functional API\n",
    "inputs = keras.layers.Input(shape=(4, ))\n",
    "embed_output = keras.layers.Embedding(vocab_size, emb_size)(inputs)\n",
    "pooled_output = tf.reduce_mean(embed_output, axis = 1)\n",
    "hidden_layer = keras.layers.Dense(hidden_dimension, 'relu')(pooled_output)\n",
    "outputs = keras.layers.Dense(output_dimension, 'sigmoid')(hidden_layer)\n",
    "model = keras.Model(inputs, outputs, name = 'Functional_API')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6903 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6699 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6523 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6325 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6113 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5859 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5576 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5234 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4845 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4407 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3950 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3447 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2942 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2459 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2003 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1617 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1250 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0992 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0758 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0454 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.9496e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.7093e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.4449e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.2173e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.9931e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.7613e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.5568e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.3511e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.1357e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.9421e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.7760e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.5851e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.4014e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.2526e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.0829e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.9428e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7858e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6292e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.4884e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.3496e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.2199e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.0997e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.9718e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.8408e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.7399e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.6172e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45e073fa30>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(input_sequence, targets, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"subclassing\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  2688      \n",
      "                                                                 \n",
      " hidden (Dense)              multiple                  33024     \n",
      "                                                                 \n",
      " output (Dense)              multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Subclassing\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dimension, hidden_dimension, output_dimension):\n",
    "        super(CustomModel, self).__init__(name = 'subclassing')\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embed_dimension, name = 'embedding')\n",
    "        self.dense_layer = keras.layers.Dense(hidden_dimension, 'relu', name = 'hidden')\n",
    "        self.output_layer = keras.layers.Dense(output_dimension, 'sigmoid', name = 'output')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = tf.reduce_mean(x, axis = 1)\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "mycustom_model = CustomModel(vocab_size, emb_size, hidden_dimension, output_dimension)\n",
    "\n",
    "mycustom_model.build(input_shape=(1, 4))\n",
    "mycustom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6917 - acc: 0.6667\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6720 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6566 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6370 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6185 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5971 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5703 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5427 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5097 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4737 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4298 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3877 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3410 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2942 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2487 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2053 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1673 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1319 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1057 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0808 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0493 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.9459e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.6618e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.4290e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.1883e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.9603e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.7383e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.5258e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.3197e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.1179e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.9404e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.7779e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.5786e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.3965e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.2448e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.0784e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.9142e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7823e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6340e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.4935e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.3652e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.2100e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.0992e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9656e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45f00ff9a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycustom_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "mycustom_model.fit(input_sequence, targets, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "iris_dataset = load_iris()\n",
    "print(iris_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['target'])\n",
    "print(iris_dataset['target_names'])\n",
    "print(iris_dataset['feature_names'])\n",
    "print(iris_dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.DataFrame(iris_dataset['data'])\n",
    "iris.columns = iris_dataset['feature_names']\n",
    "iris['target'] = iris_dataset['target']\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa = iris[iris['target'] == 0]\n",
    "versicolour = iris[iris['target'] == 1]\n",
    "virginica = iris[iris['target'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(setosa['sepal length (cm)'], setosa['sepal width (cm)'], marker='o', c='b', label='setosa')\n",
    "plt.scatter(versicolour['sepal length (cm)'], versicolour['sepal width (cm)'], marker='^', c='r', label='versicolour')\n",
    "plt.scatter(virginica['sepal length (cm)'], virginica['sepal width (cm)'], marker='*', c='g', label='virginica')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_target, test_target = train_test_split(iris_dataset['data'], iris_dataset['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, test_input.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6 3.6 1.  0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.2 4.1 1.5 0.1]]\n",
      "[[-1.47393679  1.20365799 -1.56253475 -1.31260282]\n",
      " [-0.13307079  2.99237573 -1.27600637 -1.04563275]\n",
      " [ 1.08589829  0.08570939  0.38585821  0.28921757]\n",
      " [-1.23014297  0.75647855 -1.2187007  -1.31260282]\n",
      " [-1.7177306   0.30929911 -1.39061772 -1.31260282]\n",
      " [ 0.59831066 -1.25582892  0.72969227  0.95664273]\n",
      " [ 0.72020757  0.30929911  0.44316389  0.4227026 ]\n",
      " [-0.74255534  0.98006827 -1.27600637 -1.31260282]\n",
      " [-0.98634915  1.20365799 -1.33331205 -1.31260282]\n",
      " [-0.74255534  2.32160658 -1.27600637 -1.44608785]]\n"
     ]
    }
   ],
   "source": [
    "print(train_input[:10, :10])\n",
    "print(train_scaled[:10, :10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-최근접 이웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_scaled, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = np.array([[6.1, 2.3, 1.5, 6.2]])\n",
    "new_scaled = ss.transform(new_input)\n",
    "predict = knn.predict(new_scaled)\n",
    "print(predict)\n",
    "\n",
    "knn.predict_proba(new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = knn.predict(test_scaled)\n",
    "print(predict_test)\n",
    "\n",
    "np.mean(predict_test == test_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-평균 군집화(K-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasper/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means = KMeans(n_clusters=3)\n",
    "k_means.fit(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 2 2 0 2 1 2 2 1 0 0 0 0 2 1 2 2 1 0 2 0 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "new_input = np.array([[6.1, 2.3, 1.5, 6.2]])\n",
    "new_scaled = ss.transform(new_input)\n",
    "predict = k_means.predict(new_scaled)\n",
    "\n",
    "predict_cluster = k_means.predict(test_input)\n",
    "print(predict_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 2, 1, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array(predict_cluster)\n",
    "np_arr[np_arr==0], np_arr[np_arr==1], np_arr[np_arr==2] = 3, 4, 5\n",
    "np_arr[np_arr==3] = 1\n",
    "np_arr[np_arr==4] = 2\n",
    "np_arr[np_arr==5] = 0\n",
    "predict_label = np_arr.tolist()\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict_label==test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
