{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 텐서플로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(filters = 10, kernel_size = 3, padding = 'same', activation = 'relu')(dropout)\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size = 3, padding = 'same')(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "hidden = tf.keras.layers.Dense(50, 'relu')(flatten)\n",
    "output = tf.keras.layers.Dense(10, 'softmax')(hidden)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 텐서플로 2.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequential API (순차적 레이어 스택 구현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=32, )\n",
    "x = layers.Dense(64, activation = 'relu')(inputs)\n",
    "x = layers.Dense(64, activation = 'relu')(x)\n",
    "predictions = layers.Dense(10, activation = 'softmax')(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subclassing (자유도 높음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, hidden_dimension, hidden_dimension2, output_dimension):\n",
    "        super(MyModel, self).__init__(name = 'my model')\n",
    "        self.dense_layer1 = layers.Dense(hidden_dimension, activation = 'relu')\n",
    "        self.dense_layer2 = layers.Dense(hidden_dimension2, activation = 'relu')\n",
    "        self.dense_layer3 = layers.Dense(output_dimension, activation = 'softmax')\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_layer1(inputs)\n",
    "        x = self.dense_layer2(x)\n",
    "        x = self.dense_layer3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 더미 데이터로 확인 (텍스트의 긍정/부정 예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "sampels = ['너 오늘 이뻐 보인다', '나는 오늘 기분이 더러워', '끝내주는데, 좋은 일이 있나봐', '나 좋은 일이 생겼어', '아 오늘 진짜 짜증나', '환상적인데, 정말 좋은거 같아']\n",
    "labels = [[1], [0], [1], [1], [0], [1]] # 긍정 1 부정 0\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(sampels)\n",
    "sequences = tokenizer.texts_to_sequences(sampels)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "vocab_size = len(word_index) + 1\n",
    "emb_size = 128\n",
    "hidden_dimension = 256\n",
    "output_dimension = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential API\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, emb_size, input_length = 4))\n",
    "model.add(layers.Lambda(lambda x: tf.reduce_mean(x, axis = 1)))\n",
    "model.add(layers.Dense(hidden_dimension, 'relu'))\n",
    "model.add(layers.Dense(output_dimension, 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.7835e-04 - acc: 1.0000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.7407e-04 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6177e-04 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.7172e-05 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.0539e-05 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.2542e-05 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.1071e-05 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.3524e-05 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.8302e-05 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4588e-05 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2102e-05 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0571e-05 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 9.3651e-06 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 8.1820e-06 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.3743e-06 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.8604e-06 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.2759e-06 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5.8633e-06 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5.4367e-06 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5.1918e-06 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4.8784e-06 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4.7021e-06 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4.4729e-06 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 4.2443e-06 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4.0918e-06 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.9135e-06 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.7945e-06 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.6355e-06 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.4886e-06 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.3692e-06 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.2588e-06 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.1318e-06 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.0379e-06 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.9536e-06 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8419e-06 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.7413e-06 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.6702e-06 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.5882e-06 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5209e-06 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.4414e-06 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.3550e-06 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.3043e-06 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.2335e-06 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1686e-06 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1099e-06 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0481e-06 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.9990e-06 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9560e-06 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9015e-06 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8482e-06 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8053e-06 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7531e-06 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7170e-06 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6722e-06 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6291e-06 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.5971e-06 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5592e-06 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5176e-06 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4864e-06 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4544e-06 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4197e-06 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3921e-06 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3629e-06 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3266e-06 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3046e-06 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2767e-06 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2460e-06 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2258e-06 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1962e-06 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1726e-06 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1522e-06 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1311e-06 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1078e-06 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0867e-06 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0682e-06 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0448e-06 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0283e-06 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0072e-06 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.9217e-07 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.6988e-07 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 9.5604e-07 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.3818e-07 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.2263e-07 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.0586e-07 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.9082e-07 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.7393e-07 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 8.6196e-07 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 8.4656e-07 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.3133e-07 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.1712e-07 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 8.0534e-07 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.9272e-07 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.7880e-07 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.6666e-07 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.5580e-07 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.4424e-07 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.3428e-07 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.2250e-07 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.1080e-07 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.0006e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f283654e590>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "model.fit(sequences, labels, epochs = num_epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6922 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6735 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6568 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6405 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6195 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5977 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5731 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5453 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5134 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4734 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4321 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3848 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3376 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2891 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2422 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1991 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1587 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1292 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1004 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0624 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0373 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.7887e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.5632e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.3149e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.0507e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.8191e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.6282e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.4122e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.2191e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.0212e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.8430e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.6515e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.4786e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.3263e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.1593e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6.9958e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.8200e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7057e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.5510e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.4114e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6.2871e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.1488e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.0344e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.9142e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2834ea3d30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Functional API\n",
    "inputs = layers.Input(shape = (4, ))\n",
    "embed_output = layers.Embedding(vocab_size, emb_size)(inputs)\n",
    "pooled_output = tf.reduce_mean(embed_output, axis = 1)\n",
    "hidden_layer = layers.Dense(hidden_dimension, 'relu')(pooled_output)\n",
    "outputs = layers.Dense(output_dimension, 'sigmoid')(hidden_layer)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "model.fit(sequences, labels, epochs = num_epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6931 - acc: 0.6667\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6719 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6549 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6378 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6175 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5935 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5680 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5352 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5016 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4612 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4165 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3710 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3230 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2759 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2297 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1886 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1505 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1201 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0944 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0368 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.7689e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.5105e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.2521e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.0326e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.7626e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 8.5464e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.3278e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.1209e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.9315e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.7259e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.5508e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.3536e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.1750e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.0152e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6.8512e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6870e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.5418e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.3860e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.2446e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.1177e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.9653e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.8461e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5.7224e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.6129e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.4850e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2834dd0b80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Subclassing\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dimension, hidden_dimension, output_dimension):\n",
    "        super(CustomModel, self).__init__(name = 'my_model')\n",
    "        self.embedding = layers.Embedding(vocab_size, embed_dimension)\n",
    "        self.dense_layer = layers.Dense(hidden_dimension, 'relu')\n",
    "        self.output_layer = layers.Dense(output_dimension, 'sigmoid')\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = tf.reduce_mean(x, axis = 1)\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "model = CustomModel(vocab_size, emb_size, hidden_dimension, output_dimension)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "model.fit(sequences, labels, epochs = num_epochs, batch_size = batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 사이킷런"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "# 아이리스 데이터 셋\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "print(iris_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]] (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['data'], iris_dataset['data'].shape) # 150개의 데이터가 4개의 특성을 가지고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['feature_names']) # 4개의 특징값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['target'])\n",
    "print(iris_dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['DESCR']) # 전체적인 요약 정보"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_target, test_target = train_test_split(iris_dataset['data'], iris_dataset['target'], test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4) (38, 4)\n",
      "(112,) (38,)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, test_input.shape)\n",
    "print(train_target.shape, test_target.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 지도 학습 (정답이 있는 경우 각 데이터의 정답을 예측할 수 있게 학습시키는 과정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K 최근접 이웃 분류기\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "new_input = np.array([[6.1, 2.8, 4.7, 1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(new_input) # 1로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "predict_label = knn.predict(test_input)\n",
    "print(predict_label)\n",
    "print(np.mean(predict_label == test_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 비지도 학습(데이터에 대한 정답을 사용하지 않고 만들수 있는 모델, 정답이 없을 때 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K 평균 군집화(Clustering)\n",
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3) # 3개의 군집을 만들어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasper/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.fit(train_input) # target을 넣지않음. 없으니까."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 1, 0, 2, 1, 0, 2, 2, 2, 0,\n",
       "       0, 2, 2, 2, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 1, 2,\n",
       "       2, 0, 1, 2, 0, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 2, 0, 1, 2, 2, 2, 0,\n",
       "       1, 2, 1, 1, 2, 0, 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0,\n",
       "       1, 1, 2, 0, 1, 1, 2, 1, 2, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2,\n",
       "       0, 1], dtype=int32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_ # 자동으로 라벨링 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 1 2 1]\n",
      "[2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_target[k_means.labels_ == 0])\n",
    "print(train_target[k_means.labels_ == 1])\n",
    "print(train_target[k_means.labels_ == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "prediction = k_means.predict(new_input)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 0 2 0 1 0 0 1 2 2 2 2 0 1 0 0 1 2 0 2 1 1 1 1 1 2 2 2 2 0 2 2 0 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "predict_cluster = k_means.predict(test_input)\n",
    "print(predict_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 1, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array(predict_cluster)\n",
    "np_arr[np_arr == 0], np_arr[np_arr == 1], np_arr[np_arr == 2] = 3, 4, 5\n",
    "np_arr[np_arr == 3] = 1\n",
    "np_arr[np_arr == 4] = 2\n",
    "np_arr[np_arr == 5] = 0\n",
    "predict_label = np_arr.tolist()\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict_label == test_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 사이킷런을 이용한 특징 추출(텍스트 데이터에서 단어나 문장들을 어떤 특징 값으로 바꿔주는 것을 의미)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CountVectorizer (횟수를 기준으로 특징 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer.fit(text_data)\n",
    "print(count_vectorizer.vocabulary_) # 생성된 단어사전 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[0]]\n",
    "print(count_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TfidVectorizer\n",
    "- 조사나 지시대명사 처럼 자주 등장하는 단어는 TF값(데이터 안에서 등장하는 횟수)가 크지만\n",
    "- IDF 값(문서 빈도 값)은 작아지므로 CountVectorizer가 가진 문제점 해결할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
      "[[0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "sentence = [text_data[3]]\n",
    "print(tfidf_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 자연어 토크나이징 도구\n",
    "- 토크나이징: 텍스트에 대해 특정 기준 단위로 문장을 나누는 것"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 한글 토크나이징(KoNLPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 형태소 단위 토크나이징\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']\n",
      "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '하다', 'ㅎㅎㅎ']\n"
     ]
    }
   ],
   "source": [
    "text = '한글 자연어 처리는 재밌다 이제부터 열심히 해야지 ㅎㅎㅎ'\n",
    "\n",
    "print(okt.morphs(text)) # 형태소 단위\n",
    "print(okt.morphs(text, stem=True)) # 형태소 단위로 나눈 후 어간 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '이제']\n",
      "['한글', '한글 자연어', '한글 자연어 처리', '이제', '자연어', '처리']\n"
     ]
    }
   ],
   "source": [
    "print(okt.nouns(text)) # 명사\n",
    "print(okt.phrases(text)) # 어절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('재밌다', 'Adjective'), ('이제', 'Noun'), ('부터', 'Josa'), ('열심히', 'Adverb'), ('해야지', 'Verb'), ('ㅎㅎㅎ', 'KoreanParticle')]\n",
      "['한글/Noun', '자연어/Noun', '처리/Noun', '는/Josa', '재밌다/Adjective', '이제/Noun', '부터/Josa', '열심히/Adverb', '해야지/Verb', 'ㅎㅎㅎ/KoreanParticle']\n"
     ]
    }
   ],
   "source": [
    "print(okt.pos(text)) # 품사 태깅\n",
    "print(okt.pos(text, join=True)) # 형태소+품사 리스트\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
